[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "Beyond the 3-Point Revolution: A Deep Dive into NBA Shot Selection by Position and Distance\n\n\nHow different positions have adapted to the changing landscape of NBA shooting\n\n\n\ncode\n\nanalysis\n\nNBA\n\n\n\n\n\n\n\n\n\nAug 1, 2025\n\n\nMatan Hakim\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducing il.cbs.muni - An R Package for handling Israeli CBS Municipal Data\n\n\nStreamlining Israeli Municipal Data Analysis\n\n\n\nR\n\npackages\n\nrelease\n\nCRAN\n\ndata\n\n\n\n\n\n\n\n\n\nFeb 13, 2025\n\n\nMatan Hakim\n\n\n\n\n\n\n\n\n\n\n\n\nHeight per Minute - Analyzing Height Trends in the NBA\n\n\n\n\n\n\ncode\n\nanalysis\n\nNBA\n\n\n\n\n\n\n\n\n\nSep 9, 2023\n\n\nMatan Hakim\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducing rtlr - an R Package for RTL Languages\n\n\nConvenience functions to make some common tasks with right-to-left string printing easier, more convenient and with no need to remember long Unicode characters. Specifically helpful for right-to-left languages such as Arabic, Persian and Hebrew.\n\n\n\nnews\n\ncode\n\nrtlr\n\nRWeekly Highlights\n\n\n\n\n\n\n\n\n\nApr 5, 2023\n\n\nMatan Hakim\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023-04-05-rtlr-0-1-0/index.html",
    "href": "posts/2023-04-05-rtlr-0-1-0/index.html",
    "title": "Introducing rtlr - an R Package for RTL Languages",
    "section": "",
    "text": "(This blog post was chosen as a highlight for R Weekly issue 2023-W15)\nDo you know anyone who speaks Arabic, Persian or Hebrew? Do you know any R professional who speaks any of these languages? Maybe you are yourself an R professional who speaks any of these languages and uses them in your R work?\nTL;DR - You can use rtlr to fix right-to-left problems in R. install the package with install.packages(\"rtlr\") and use str_rtl() with your text as argument(s)."
  },
  {
    "objectID": "posts/2023-04-05-rtlr-0-1-0/index.html#footnotes",
    "href": "posts/2023-04-05-rtlr-0-1-0/index.html#footnotes",
    "title": "Introducing rtlr - an R Package for RTL Languages",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://www.w3.org/International/questions/qa-scripts‚Ü©Ô∏é\nFor further reading on this, see: https://unicode.org/reports/tr9/#Directional_Formatting_Characters‚Ü©Ô∏é\nThis is because \\n stops the RTL-embedding provided by \\u202B, and forces you to write this as \\n\\u202B instead.‚Ü©Ô∏é"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Matan Hakim - CV",
    "section": "",
    "text": "2018 - Present: Co-Founder and Head of Research, The Israeli Institute for Cultural Policy\n2022 - Present: Socio-Economic Research Fellow, Arlozorov Forum\n2018 - 2021: Psychometric Exam Teacher, Kidum\n2017 - 2018: Physics and Math Teacher, Atidim\n2015 - 2017: Head of Digital, Tarbut Movement"
  },
  {
    "objectID": "cv.html#open-source-contributions",
    "href": "cv.html#open-source-contributions",
    "title": "Matan Hakim - CV",
    "section": "Open Source contributions",
    "text": "Open Source contributions\n\nAuthor and maintainer of rtlr, an R package for RTL languages\nFeature development in janitor, an R package for examining and cleaning dirty data\nProofreading contributions to the open-source books:\n\nR for Data Science (2e)\nR Packages (2e)\nBuilding reproducible analytical pipelines with R"
  },
  {
    "objectID": "cv.html#publications",
    "href": "cv.html#publications",
    "title": "Matan Hakim - CV",
    "section": "Publications",
    "text": "Publications\n\nYoung People in the Labor Market in Israel (2024), Arlozorov Forum\nThe Want of Job Switching: Analysis of Situation and Trends in Israel (2024), Arlozorov Forum\nThe Israeli Guide for Cultural Mapping (2023), the Israeli Institute for Cultural Policy (under review)\nData Analysis 2011-2021 - Culture in Israel in a Regional Perspective (2023), the Israeli Institute for Cultural Policy (submitted to the Israeli Parliament)\nCulture as an Israeli Growth Driver (2020), Tarbut Movement (submitted to the Israeli Parliament)\nCultural Policy Data (2020), Tarbut Movement (submitted to the Israeli Parliament)"
  },
  {
    "objectID": "cv.html#talks",
    "href": "cv.html#talks",
    "title": "Matan Hakim - CV",
    "section": "Talks",
    "text": "Talks\n\nData on the Cultural Field in Israel (2023), presented in the Israeli Parliament, Special Committee for Strengthening and Developing the Negev and Galilee\nCultural Policy and Local Governments: Between Inequalities and Political Compensation (2022), presented in the Annual Conference of the Israeli Sociological Society\n\nA draft of this talk was also presented in the University of Haifa Young Researchers Forum of the Interdisciplinary Center for the Study of Poverty and Social Exclusion (2021)\n\nInequality in Israel (2020), presented in the Balfur Protest Organization Meeting\nChristian Motives in ‚ÄúKehilyatenu‚Äù (2020), presented in the Annual Conference of the Israeli Labor Movement Research Forum\nThe Privatization of the Israeli Pension System (2017), Beit Berl Academic College"
  },
  {
    "objectID": "cv.html#footnotes",
    "href": "cv.html#footnotes",
    "title": "Matan Hakim - CV",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee this TheMarker news article‚Ü©Ô∏é"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Matan Hakim - Policy Data Scientist",
    "section": "",
    "text": "Head of Research at the Israeli Institute for Cultural Policy.\nI lead projects in data science, research, analytics, and social and economic policy."
  },
  {
    "objectID": "posts/2023-09-09-nba-heights/index.html#setup",
    "href": "posts/2023-09-09-nba-heights/index.html#setup",
    "title": "Height per Minute - Analyzing Height Trends in the NBA",
    "section": "Setup",
    "text": "Setup\nLet‚Äôs load the relevant packages.\n\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(janitor)\nlibrary(scales)\nlibrary(jtools)\nlibrary(gganimate)\nlibrary(conflicted)\nconflicts_prefer(dplyr::filter())"
  },
  {
    "objectID": "posts/2023-09-09-nba-heights/index.html#import-data",
    "href": "posts/2023-09-09-nba-heights/index.html#import-data",
    "title": "Height per Minute - Analyzing Height Trends in the NBA",
    "section": "Import data",
    "text": "Import data\n\nTotal minutes played for every player in every season\nLet‚Äôs start by defining a function to read the data on every player on a specific season. This is where the ‚Äúminutes played‚Äù stat comes from, so it‚Äôs important. This function scrapes the Basketball Reference website using the rvest package, and returns a tibble of every player‚Äôs name registered in that season, alongside its position, age, and minutes played. You‚Äôll see why position and age matter in a minute!\n\nread_season &lt;- function(year) {\n1  Sys.sleep(4)\n  read_html(str_c(\"https://www.basketball-reference.com/leagues/NBA_\", year, \"_totals.html\")) |&gt; \n    html_element(\"table\") |&gt; \n    html_table() |&gt; \n    clean_names() |&gt; \n2    filter(str_detect(rk, \"[:digit:]\")) |&gt;\n    select(player, pos, age, mp)\n}\n\n\n1\n\nPause between requests to avoid hitting the rate limit of 20 requests in a minute.\n\n2\n\nRemove repeating header rows.\n\n\n\n\nAfter defining our function, let‚Äôs map it over every season, starting from 1952.\n\ndf_seasons_raw &lt;- tibble(year = 1952:2023) |&gt;\n  mutate(data = map(year, read_season)) |&gt;\n  unnest(data)\n\n\n\nAll players\nIn our previously collected data set we don‚Äôt have any data on the players‚Äô heights! So, we need to collect this for every player to ever play in the league. This function reads data for all players whos family name starts with the same letter. it returns a tibble with player name, NBA carreer first and last year, height, position, birth date and college.\n\nread_players_letter &lt;- function(letter) {\n1  Sys.sleep(4)\n  read_html(str_c(\"https://www.basketball-reference.com/players/\", letter)) |&gt; \n    html_element(\"table\") |&gt; \n    html_table() |&gt; \n    clean_names() |&gt; \n2    filter(str_detect(from, \"[:digit:]\")) |&gt;\n3    mutate(player = str_remove_all(player, \"\\\\*\"))\n}\n\n\n1\n\nPause between requests to avoid hitting the rate limit of 20 requests in a minute.\n\n2\n\nRemove repeating header rows.\n\n3\n\nRemove asterisk from player name (indicating members of the Hall of Fame).\n\n\n\n\nNow, let‚Äôs map this function over every letter (besides ‚Äúx‚Äù, a letter with no NBA players family names) to create our data set.\n\nletters_no_x &lt;- letters[letters != \"x\"]\ndf_players_raw &lt;- map(letters_no_x, read_players_letter) |&gt;\n  list_rbind()"
  },
  {
    "objectID": "posts/2023-09-09-nba-heights/index.html#manipulate-data",
    "href": "posts/2023-09-09-nba-heights/index.html#manipulate-data",
    "title": "Height per Minute - Analyzing Height Trends in the NBA",
    "section": "Manipulate data",
    "text": "Manipulate data\n\nJoin data frames\nIf we have tried joining the two data sets, we would encounter a problem: some NBA players have the same name! Let‚Äôs see this:\n\ndf_players_raw |&gt; \n  count(player, sort = TRUE) |&gt; \n  head(n = 10) |&gt; \n  knitr::kable()\n\n\n\n\nplayer\nn\n\n\n\n\nCharles Jones\n3\n\n\nCharles Smith\n3\n\n\nGeorge Johnson\n3\n\n\nBill Bradley\n2\n\n\nBob Duffy\n2\n\n\nBobby Jones\n2\n\n\nBobby Wilson\n2\n\n\nBrandon Williams\n2\n\n\nCedric Henderson\n2\n\n\nChris Johnson\n2\n\n\n\n\n\nWe have 3 different players for each of Charles Jones, Charles Smith, and George Johnson! We need to come up with a way to differentiate between them. This is where birth date comes in.\n\ndf_players &lt;- df_players_raw |&gt; \n1  separate(ht, into = c(\"ht_feet\", \"ht_inches\"), sep = \"-\", remove = FALSE) |&gt;\n  mutate(\n2    ht_tot_inches = parse_double(ht_feet) * 12 + parse_double(ht_inches),\n    ht_tot_cm = ht_tot_inches * 2.54,\n3    birth_date = parse_date_time(birth_date, \"bdy\"),\n    birth_year = year(birth_date),\n4    birth_year_effective = if_else(\n      month(birth_date) &gt; 1,\n      birth_year + 1,\n      birth_year\n    )\n  )\n\n\n1\n\nSeparate height to feet and inches.\n\n2\n\nCalculate total height.\n\n3\n\nextract birth year from birth date.\n\n4\n\nCalculate effective birth year - the player‚Äôs age shown is its age during February 1st of that season.\n\n\n\n\n\ndf_seasons &lt;- df_seasons_raw |&gt; \n  mutate(\n1    player = str_remove_all(player, \"\\\\*\"),\n    birth_year_effective = year - age\n  )\n\n\n1\n\nRemove asterisk from player name (indicating members of the Hall of Fame).\n\n\n\n\nNow we‚Äôre ready to join the data sets by name and by birth year.\n\ndf_all &lt;- df_seasons |&gt; \n  left_join(df_players, join_by(player, birth_year_effective)) |&gt; \n  mutate(\n1    decade = (year - year %% 10) |&gt;\n      factor() |&gt;\n      str_c(\"'s\")\n  )\n\n\n1\n\nCalculate decade, turn it to a factor and add an ‚Äú‚Äôs‚Äù prefix.\n\n\n\n\n\n\nCalculate (weighted) mean height\nLet‚Äôs define a function to calculate a weighted mean height by one or more variables.\n\nweighted_mean_by &lt;- function(data, mean_var, by_vars, weights) {\n  data |&gt; \n1    group_by({{ by_vars }}) |&gt;\n    summarise(\n      mean = weighted.mean({{ mean_var }}, {{ weights }}),\n      sd = wtd.sd({{ mean_var }}, {{ weights }}),\n      sd_upper = mean + sd,\n      sd_lower = mean - sd,\n      .groups = \"drop\"\n    )\n}\n\n\n1\n\nThe double curly brackets use the idea of ‚Äútidy evaluation‚Äù. for more on this, go to R4DS (2e)\n\n\n\n\nLet‚Äôs calculate these stats for every year and for every decade.\n\ndf_mean_years &lt;- df_all |&gt; \n  weighted_mean_by(ht_tot_inches, year, mp)\n\ndf_mean_decades &lt;- df_all |&gt; \n  weighted_mean_by(ht_tot_inches, decade, mp)\n\n\n\nCalculate (weighted) frequency by minutes played\nNow, Let‚Äôs get to the heart of this analysis. We‚Äôll define a function that takes all of the NBA players, and calculates the weighted relative frequency of every height for a specific period. In simpler words, it computes the percent of minutes played by every height during a year or a decade.\n\nsummarize_heigths &lt;- function(data, var, by_vars, weights = NULL) {\n  data |&gt; \n    count({{ by_vars }}, {{ var }}, wt = {{ weights }}) |&gt; \n    mutate(\n      .by = {{ by_vars }},\n      pct = n / sum(n),\n    )\n}\n\ndf_heights_years &lt;- df_all |&gt; \n  summarize_heigths(ht_tot_inches, by_vars = year, weights = mp)\n\ndf_heights_decades &lt;- df_all |&gt;\n  summarize_heigths(ht_tot_inches, by_vars = decade, weights = mp)"
  },
  {
    "objectID": "posts/2023-09-09-nba-heights/index.html#visualization",
    "href": "posts/2023-09-09-nba-heights/index.html#visualization",
    "title": "Height per Minute - Analyzing Height Trends in the NBA",
    "section": "Visualization",
    "text": "Visualization\n\nUtility functions\nThis function converts a height from inches only (which is better for computation) to a feet-inches format (which is better for presentation).\n\ninches_to_feet &lt;- function(x) {\n  str_c(\n    x %/% 12,\n    x %% 12,\n    sep = \"-\"\n  )\n}\n\nThese will serve us for more reasonable axes labels.\n\nbreaks_height &lt;- (23:29) * 3\nlabels_height &lt;- inches_to_feet(breaks_height)\n\n\n\nMean height by year\n\np1 &lt;- df_mean_years |&gt; \n  ggplot(aes(year, mean)) +\n  geom_line() +\n  geom_point() + \n  scale_y_continuous(labels = inches_to_feet) +\n  scale_x_continuous(breaks = seq(1950, 2020, 10)) +\n  labs(\n    title = \"NBA players' average height has dropped over the last 20 years\",\n    subtitle = \"2023 featured a spike in average height\",\n    x = \"Year\",\n    y = \"Mean Height (feet-inches)\",\n    caption = \"Data: basketball-reference.com. Analysis: Matan Hakim.\"\n  )\n\n\n\nStandard deviation by year\n\np2 &lt;- df_mean_years |&gt; \n  ggplot(aes(year, sd)) +\n  geom_line() +\n  geom_point() +\n  scale_x_continuous(breaks = seq(1950, 2020, 10)) +\n  labs(\n    title = \"Since 1995, NBA players are becoming more similar in their height\",\n    subtitle = \"The early 1990's were the time with most variability in player heights\",\n    x = \"Year\",\n    y = \"Standard Deviation (inches)\",\n    caption = \"Data: basketball-reference.com. Analysis: Matan Hakim.\"\n  )\n\n\n\nDistribution by decade\n\np3 &lt;- df_heights_decades |&gt; \n  ggplot(aes(ht_tot_inches, pct)) + \n  geom_line() + \n  geom_vline(data = df_mean_decades, aes(xintercept = mean), linetype = \"dashed\") +\n  facet_wrap(~ decade, ncol = 1, strip.position = \"right\") +\n  scale_x_continuous(breaks = breaks_height, labels = labels_height) +\n  coord_cartesian(xlim = range(breaks_height)) +\n  scale_y_continuous(labels = label_percent()) +\n  labs(\n    title = str_wrap(\n      \"Since the 2000's NBA players are becoming shorter and more similar in their height\",\n      width = 60\n    ),\n    subtitle = \"Average height represented as dashed line\",\n    x = \"Height (feet-inches)\",\n    y = \"% of minutes played\",\n    caption = \"Data: basketball-reference.com. Analysis: Matan Hakim.\"\n  )"
  },
  {
    "objectID": "posts/2023-09-09-nba-heights/index.html#distribution-by-year-animation",
    "href": "posts/2023-09-09-nba-heights/index.html#distribution-by-year-animation",
    "title": "Height per Minute - Analyzing Height Trends in the NBA",
    "section": "Distribution by year (animation)",
    "text": "Distribution by year (animation)\nFor this last plot, we will unlock the amazing potential of the gganimate package.\n\np4 &lt;- df_heights_years |&gt; \n  left_join(df_mean_years, join_by(year)) |&gt; \n  ggplot(aes(ht_tot_inches, pct)) +\n  geom_line() +\n  scale_y_continuous(labels = label_percent()) +\n  scale_x_continuous(breaks = breaks_height, labels = labels_height) +\n  coord_cartesian(xlim = range(breaks_height)) +\n  transition_time(year) +\n  geom_vline(\n    aes(xintercept = mean),\n    linetype = \"dashed\"\n  ) +\n  labs(\n    title = str_c(\n      \"Year: {frame_time}, Distribution of NBA Players' Height\",\n      \"\\n\",\n      \"(Weighted by Minutes Played)\"\n    ),\n    subtitle = \"Average height represented as dashed line\",\n    x = \"Height (feet-inches)\",\n    y = \"% of minutes played\",\n    caption = \"Data: basketball-reference.com. Analysis: Matan Hakim.\"\n  ) +\n    shadow_mark(past = FALSE, future = FALSE)"
  },
  {
    "objectID": "example.html",
    "href": "example.html",
    "title": "",
    "section": "",
    "text": "df_freq_tot &lt;- read_rds(\"df_freq_tot.rds\")\ndf_freq &lt;- read_rds(\"df_freq.rds\")\n\n\nlibrary(ggiraph)\n\nWarning: package 'ggiraph' was built under R version 4.4.3\n\nplot1 &lt;- df_freq |&gt; \n  filter(!(dist %in% c(\"2p\", \"dunk\"))) |&gt; \n  ggplot(aes(year, freq, color = pos, tooltip = pos, data_id = pos)) +\n  geom_line_interactive(linewidth = 1) +\n  facet_wrap(~ dist, scales = \"free_y\") +\n  scale_y_continuous(labels = label_percent()) +\n  scale_color_solarized() +\n  labs(\n    x = \"\",\n    y = \"Shot Frequency\",\n    color = \"Position\",\n    title = \"Shot Frequency by Year, Position and Distance from the Basket\",\n    subtitle = \"How the 3-point revolution affected different positions\",\n    caption = \"Data: basketball-reference.com. Analysis: Matan Hakim.\"\n  )\n\ngirafe(ggobj = plot1)\n\n\n\n\n\n\ndf_freq |&gt; \n  filter(!(dist %in% c(\"2p\", \"dunk\"))) |&gt; \n  ggplot(aes(year, freq, color = pos)) +\n  geom_line(linewidth = 1) +\n  facet_wrap(~ dist, scales = \"free_y\") +\n  scale_y_continuous(labels = label_percent()) +\n  scale_color_solarized() +\n  labs(\n    x = \"\",\n    y = \"Shot Frequency\",\n    color = \"Position\",\n    title = \"Shot Frequency by Year, Position and Distance from the Basket\",\n    subtitle = \"How the 3-point revolution affected different positions\",\n    caption = \"Data: basketball-reference.com. Analysis: Matan Hakim.\"\n  )"
  },
  {
    "objectID": "posts/2025-02-08-nba-shot-selection/index.html#setup",
    "href": "posts/2025-02-08-nba-shot-selection/index.html#setup",
    "title": "Beyond the 3-Point Revolution: A Deep Dive into NBA Shot Selection by Position and Distance",
    "section": "Setup",
    "text": "Setup\nLet‚Äôs load the relevant packages.\n\n1library(tidyverse)\n2library(rvest)\n3devtools::install_github(\"sfirke/janitor\")\nlibrary(janitor)\n4library(scales)\n5library(ggthemes)\n6library(ggiraph)\n7library(conflicted)\nconflicts_prefer(dplyr::filter())\n\n\n1\n\nThe tidyverse is my favorite data analysis framework, and we‚Äôll be using it for wrangling and visualization.\n\n2\n\nrvest is for web-scraping, that‚Äôs how we‚Äôre going to get our data.\n\n3\n\nI‚Äôm installing the development version of janitor (one of the go-to packages for easy utility functions!) because the row_to_names() function has a specific feature (that I created! Yey!) that isn‚Äôt available in the CRAN version yet.\n\n4\n\nscales helps us format our plot axes with percentage labels and other formatting.\n\n5\n\nggthemes provides additional color palettes, including the solarized theme we‚Äôll use.\n\n6\n\nggiraph makes your plots interactive.\n\n7\n\nconflicted lets you be clear and intentional with your namespace clashes.\n\n\n\n\nNow let‚Äôs read our data from the web."
  },
  {
    "objectID": "posts/2025-02-08-nba-shot-selection/index.html#define-scraping-functions",
    "href": "posts/2025-02-08-nba-shot-selection/index.html#define-scraping-functions",
    "title": "Beyond the 3-Point Revolution: A Deep Dive into NBA Shot Selection by Position and Distance",
    "section": "Define scraping functions",
    "text": "Define scraping functions\nOur first data source is the seasonal player shooting stats table (2025 for example.). In this table, our unit of analysis is a player, and the table is for a specific season. The columns offer different breakdowns of field goal attempts frequency by distance from the basket, along with field goal percent (accuracy) by distance. The earliest data is from the 1997-1998 season (oh, the nostalgia!).\n\nread_season_dist &lt;- function(year) {\n1  Sys.sleep(4)\n  read_html(str_c(\"https://www.basketball-reference.com/leagues/NBA_\", year, \"_shooting.html\")) |&gt; \n    html_element(\"table\") |&gt; \n    html_table(header = FALSE) |&gt; \n2    row_to_names(1:2) |&gt;\n    clean_names() |&gt; \n3    mutate(across(everything(), parse_guess))\n}\n\n\n1\n\nIn order to avoid being rejected by the Basketball Reference policy, we need to wait between each visit to a page.\n\n2\n\nIn this cool new feature to {janitor} you can elevate multiple rows to act as new column names.\n\n3\n\nAfter fixing the column names, you can guess and parse the column types.\n\n\n\n\nUnfortunately, the shooting stats table is missing a very important value - the total number of shots for a player in a season. Right now we only have the frequency, but not the absolute value. We need this data to correctly calculate the relative weight of each player. Think about it: a player who takes 50 shots per season shouldn‚Äôt have the same influence on league-wide trends as someone who takes 1,500 shots. So let‚Äôs read another table, where we have this data.\n\nread_season_total &lt;- function(year) {\n  Sys.sleep(4)\n  read_html(str_c(\"https://www.basketball-reference.com/leagues/NBA_\", year, \"_totals.html\")) |&gt; \n    html_element(\"table\") |&gt; \n    html_table() |&gt; \n    clean_names()\n}\n\nNow, let‚Äôs perform the web-scraping. We are reading data from 1998 to 2025, covering nearly three decades of NBA evolution.\n\ndf_dist_raw &lt;- tibble(year = 1998:2025) |&gt; \n  mutate(data = map(year, read_season_dist)) |&gt; \n  unnest(data)\n  \ndf_players_raw &lt;-  tibble(year = 1998:2025) |&gt; \n  mutate(data = map(year, read_season_total)) |&gt; \n  unnest(data)\n\nThis process will take several minutes due to our rate limiting (we‚Äôre being good citizens of the web!). The map() function applies our scraping function to each year, and unnest() combines all the individual season data frames into two comprehensive datasets."
  },
  {
    "objectID": "posts/2025-02-08-nba-shot-selection/index.html#clean-and-join-our-datasets",
    "href": "posts/2025-02-08-nba-shot-selection/index.html#clean-and-join-our-datasets",
    "title": "Beyond the 3-Point Revolution: A Deep Dive into NBA Shot Selection by Position and Distance",
    "section": "Clean and join our datasets",
    "text": "Clean and join our datasets\nBasketball Reference data comes with some quirks that we need to handle. Players who were traded during a season appear multiple times (once for each team plus a ‚Äútotal‚Äù row), and there are various formatting issues we need to address.\n\ndf_players &lt;- df_players_raw |&gt; \n1  distinct(player, year, .keep_all = TRUE) |&gt;\n2  select(year, player, fg, fga)\n\ndf_dist &lt;- df_dist_raw |&gt; \n  distinct(player, year, .keep_all = TRUE) |&gt; \n3  select(!c(rk, awards))\n\n\n1\n\nRemove duplicate rows for players who were traded mid-season, and keep only seasonal stats.\n\n2\n\nWe only need the basic shooting volume data from this table.\n\n3\n\nRemove unnecessary columns like rank and awards.\n\n\n\n\n\ndf &lt;- df_players |&gt; \n  left_join(df_dist, join_by(player, year)) |&gt; \n1  relocate(c(fg, fga), .after = mp)\n\n\n1\n\nMove the shooting volume columns next to minutes played for logical organization."
  },
  {
    "objectID": "posts/2025-02-08-nba-shot-selection/index.html#league-wide-trends-by-distance",
    "href": "posts/2025-02-08-nba-shot-selection/index.html#league-wide-trends-by-distance",
    "title": "Beyond the 3-Point Revolution: A Deep Dive into NBA Shot Selection by Position and Distance",
    "section": "League-wide trends by distance",
    "text": "League-wide trends by distance\nLet‚Äôs start with the big picture - how has shot selection changed across the entire league?\n\nplot_total &lt;- df_freq_tot |&gt; \n1  filter(!(dist %in% c(\"2p\", \"dunk\"))) |&gt;\n2  mutate(dist = fct_reorder2(dist, year, freq)) |&gt;\n  ggplot(aes(year, freq, color = dist, tooltip = dist, data_id = dist)) +\n  geom_line_interactive(linewidth = 1) + \n  scale_y_continuous(labels = label_percent()) +\n  scale_color_solarized() +\n  labs(\n    x = \"\",\n    y = \"Shot Frequency\",\n    color = \"Distance (feet)\",\n    title = \"Shot Frequency by Year and Distance from the Basket\",\n    subtitle = \"The 3-point revolution meets the mid-range exodus\",\n    caption = \"Data: basketball-reference.com. Analysis: Matan Hakim.\"\n  )\n\ngirafe(ggobj = plot_total)\n\n\n1\n\nRemove aggregate categories to focus on specific distance ranges.\n\n2\n\nReorder the legend based on the final year values for better readability."
  },
  {
    "objectID": "posts/2025-02-08-nba-shot-selection/index.html#position-specific-trends",
    "href": "posts/2025-02-08-nba-shot-selection/index.html#position-specific-trends",
    "title": "Beyond the 3-Point Revolution: A Deep Dive into NBA Shot Selection by Position and Distance",
    "section": "Position-specific trends",
    "text": "Position-specific trends\nNow let‚Äôs see how different positions have adapted to these league-wide changes. This is where things get really interesting!\n\nplot_position &lt;- df_freq |&gt; \n  filter(!(dist %in% c(\"2p\", \"dunk\"))) |&gt; \n  ggplot(aes(year, freq, color = pos, tooltip = pos, data_id = pos)) +\n  geom_line_interactive(linewidth = 0.7) +\n1  facet_wrap(~ dist, scales = \"free_y\") +\n  scale_y_continuous(labels = label_percent()) +\n  scale_color_solarized() +\n  labs(\n    x = \"\",\n    y = \"Shot Frequency\",\n    color = \"Position\",\n    title = \"Shot Frequency by Year, Position and Distance from the Basket\",\n    subtitle = \"How the 3-point revolution affected different positions\",\n    caption = \"Data: basketball-reference.com. Analysis: Matan Hakim.\"\n  )\n\ngirafe(ggobj = plot_position)\n\n\n1\n\nUse free y-scales to better show the trends within each distance range."
  },
  {
    "objectID": "posts/2025-02-08-nba-shot-selection/index.html#the-death-of-the-mid-range-shot",
    "href": "posts/2025-02-08-nba-shot-selection/index.html#the-death-of-the-mid-range-shot",
    "title": "Beyond the 3-Point Revolution: A Deep Dive into NBA Shot Selection by Position and Distance",
    "section": "The Death of the Mid-Range Shot",
    "text": "The Death of the Mid-Range Shot\nLooking at our league-wide visualization, we can see the famous ‚Äú3-point revolution‚Äù in action, but the real story is more nuanced than the typical narrative suggests. Yes, 3-pointers have exploded from around 16% in 1998 to over 42% in 2025. But the most dramatic change is actually the systematic elimination of mid-range shots, particularly in the 16-foot to 3-point line range, which has plummeted from around 24% to just 5% over the same period.\nThis makes perfect basketball sense. A 20-foot jump shot is worth the same 2 points as a layup, but it‚Äôs much harder to make. Meanwhile, step back just a few feet and that same shot becomes worth 3 points. The math is brutal for mid-range shots.\nInterestingly enough, the 3-10 foot shot is alive and well, even showing an increase in recent years from about 15% to 21%. This reflects the uptick in ‚Äúfloater‚Äù type shots, tear-drops, push-shots, ‚Äúthe giant slayer‚Äù, and other shots taken mostly by perimeter players trying to shoot above rim-protecting big men."
  },
  {
    "objectID": "posts/2025-02-08-nba-shot-selection/index.html#position-specific-adaptations",
    "href": "posts/2025-02-08-nba-shot-selection/index.html#position-specific-adaptations",
    "title": "Beyond the 3-Point Revolution: A Deep Dive into NBA Shot Selection by Position and Distance",
    "section": "Position-Specific Adaptations",
    "text": "Position-Specific Adaptations\nWhen we break down the trends by position and distance, we see fascinating differences in how players have adapted. Each distance range tells its own story:\n0-3 feet: This shot distance serves as the main differentiator between positions - the bigger the position, the more shots come from the rim area. What‚Äôs particularly striking is how the gaps between positions have widened over time. Centers now take nearly 45% of their shots at the rim, while point guards take only about 18%. This reinforces the growing divide between ‚Äúbig-men‚Äù and ‚Äúwings‚Äù and ‚Äúsmalls‚Äù - a clear manifestation of the split between perimeter and interior players.\n3-10 feet: Interestingly, and as mentioned above, this shot distance has seen a rise in popularity, especially among guards and small forwards. The position hierarchy remains similar to rim shots, with centers leading the way, but the trends show this becoming a more valuable weapon for perimeter players navigating crowded paint areas.\n10-16 feet: Here‚Äôs where things get fascinating. The short mid-range has actually become a more common weapon in the point guard‚Äôs toolbox, even as other positions have abandoned it. The rise in popularity of this shot distance among PGs, in contrast to other positions‚Äô trends, might be attributed to the evolution of the pick-and-roll game and the need for shorter players to create effective counters. Think of ‚Äúsnaking‚Äù the pick-and-roll, a move point guards like Chris Paul and TJ McConnell have perfected.\n16 feet-3pt: This distance plot is the poster child for the death of the mid-range. Not a single position has shown willingness to maintain meaningful volume shooting from this range, as the 3-point revolution has reached its logical conclusion. This is the only shot distance where all five positions converge to the same trend - universal abandonment.\n3-point: The breakdown by position reveals that ‚Äúthe 3-point revolution‚Äù is actually four distinct sub-revolutions:\n\n‚ÄúThe Long Evolution‚Äù - Ever since the inception of the 3-point shot, its frequency has been climbing, especially among guards and forwards. This trend continued almost without interruption from 1998 to 2013.\n‚ÄúThe Power Forward Revolution‚Äù - Around 2013, power forwards‚Äô 3-point frequency saw massive increases. In 2012, small forwards shot 3-pointers three times as much as power forwards, but by 2017 they had evened out. This represents one of the most dramatic positional transformations in NBA history.\n‚ÄúThe Centers Revolution‚Äù - Between 2015 and 2020, centers more than quadrupled their 3-point shot frequency, going from barely 3% to over 15%. This trend fundamentally changed what it means to be a center in the modern NBA.\n‚ÄúThe Latest Surge‚Äù - The 2024-25 season has seen a rise in 3-point frequency among almost all positions. Whether this upward trend continues remains to be seen, but it suggests the revolution isn‚Äôt over yet."
  },
  {
    "objectID": "posts/2025-02-13-il-cbs-muni-0-1-0/index.html",
    "href": "posts/2025-02-13-il-cbs-muni-0-1-0/index.html",
    "title": "Introducing il.cbs.muni - An R Package for handling Israeli CBS Municipal Data",
    "section": "",
    "text": "I‚Äôm excited to announce that il.cbs.muni 0.1.0 is now available on CRAN! This package provides analyst-oriented utility functions to work with Israeli Central Bureau of Statistics (CBS) municipal data, handling the different quirks and inconsistencies across years and data sources.\nYou can install it from CRAN:\ninstall.packages(\"il.cbs.muni\")"
  },
  {
    "objectID": "posts/2025-02-13-il-cbs-muni-0-1-0/index.html#what-does-il.cbs.muni-do",
    "href": "posts/2025-02-13-il-cbs-muni-0-1-0/index.html#what-does-il.cbs.muni-do",
    "title": "Introducing il.cbs.muni - An R Package for handling Israeli CBS Municipal Data",
    "section": "What Does il.cbs.muni Do?",
    "text": "What Does il.cbs.muni Do?\nThe Israeli CBS publishes extensive municipal data covering cities, local councils, and regional councils. However, this data comes with challenges:\n\nInconsistent formats across different years\nDifferent Excel structures for various data domains\nMultiple ID systems used by different government agencies\nSeparate sheets for different municipality types (pre-2016)\nComplex headers that need careful processing\n\nil.cbs.muni solves these problems by providing a consistent interface to read, process, and combine Israeli municipal data from different sources and years."
  },
  {
    "objectID": "posts/2025-02-13-il-cbs-muni-0-1-0/index.html#key-features",
    "href": "posts/2025-02-13-il-cbs-muni-0-1-0/index.html#key-features",
    "title": "Introducing il.cbs.muni - An R Package for handling Israeli CBS Municipal Data",
    "section": "Key Features",
    "text": "Key Features\n\n1. Read Municipal Data Files\nIsraeli CBS provides municipal data in Excel files with different header structures between the years. Trying to combine and load multiple years requires identifying the quirks for each year making it harder to read them.\nLet‚Äôs take a look at the plain old municipal Excel data file, specifically from 2021:\n\nWe can observe multiple problems:\n\nThe headers start from the 3rd row, not the first;\nThe headers span across multiple rows, making it harder to read them;\n\nIf we toggle a bit along the columns, we can see another problem:\n\nSome column headers need to be filled horizontally, and merged with the cell below them.\nThe read_cbs_muni() function reads municipal data files with pre-configured parameters for each year‚Äôs specific quirks:\n\nlibrary(il.cbs.muni)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n# Read physical and demographic data for 2021\ndf1 &lt;- read_cbs_muni(\n  path = \"p_libud_2021.xlsx\",\n  year = 2021,\n  data_domain = \"physical\"\n)\n\ndf1\n\n\n  \n\n\n\nSupported data domains include:\n\n\"physical\" - Physical and population data\n\"budget\" - Municipal budget data\n\n\"summary\" - Summary statistics\n\"labor_force_survey\" - Labor force data\n\"social_survey\" - Social survey data\n\nNow, Let‚Äôs say you want budget data from the same year. Perhaps you would like to know the municipal expenditure on education. This is on a different data domain (i.e., worksheet). We could access it directly, and select the relevant columns with the  framework:\n\ndf2 &lt;- read_cbs_muni(\n  \"p_libud_2021.xlsx\",\n  2021,\n  data_domain = \"budget\",\n  cols = c(2, 50)\n)\n\ndf2\n\n\n  \n\n\n\nNow, if we want to join the two data frames, we can simply join by municipal ID, either by using its Hebrew variable name or by possibly renaming it:\n\ndf &lt;- df1 |&gt; \n  left_join(df2, join_by(`◊õ◊ú◊ú◊ô_◊°◊û◊ú ◊î◊®◊©◊ï◊™` == `◊°◊û◊ú ◊î◊®◊©◊ï◊™`)) |&gt; \n  relocate(contains(\"◊©◊ô◊®◊ï◊™◊ô◊ù ◊û◊û◊ú◊õ◊™◊ô◊ô◊ù: ◊ó◊ô◊†◊ï◊ö\"))\n\ndf\n\n\n  \n\n\n\nBe aware that in order to avoid wrong assumptions, all data types are configured to be character, and need to be parsed to your liking.\n\n\n2. Combine Data from Different Municipality Types\nFor years 2003-2015, CBS published data on separate sheets for cities/local councils and regional councils.\n\nUse combine_cbs_muni() to merge them:\n\n# Combine data from both sheets\ndf_combined &lt;- combine_cbs_muni(\n  path = \"2009.xls\",\n  year = 2009,\n  cols_city = c(1:7, 11),\n  cols_rc = c(1:7, 25),\n  data_domain = \"physical\"\n)\n\ndf_combined\n\n\n  \n\n\n\nPlease notice that you have to select the specific columns and match them by yourself. Unfortunately, harmonizing the entire dataset is too big of a task to handle, and would hopefully be achieved by widening the scope of the CBS API.\nHow does il.cbs.muni know how many rows to skip, which columns to fill row-wise, and what are the sheet numbers for each data domain within each year? I have taken the time to parameterize all of this data, so il.cbs.muni becomes a one-stop-shop for your data reading tasks. If you want to look under the hood, you can check out il.cbs.muni:::df_cbs_muni_params. Additionally, I wrote row_to_names_fill() as a helper function to fill row-wise some of the header rows, but it can be used also outside the scope of municipal data.\nGoing back to our data, you can see that the 10th row municipal name is littered with an asterisk (‚Äú*‚Äú). We can clean all names with clean_name():\n\ndf_combined[[10,1]]\n\n[1] \"◊ë◊ê◊ß◊î-◊í'◊™*\"\n\ndf_combined &lt;- df_combined |&gt; \n  mutate(\n    `◊©◊ù ◊î◊®◊©◊ï◊™` = clean_name(`◊©◊ù ◊î◊®◊©◊ï◊™`)\n  )\n\ndf_combined[[10,1]]\n\n[1] \"◊ë◊ê◊ß◊î-◊í'◊™\"\n\n\n\n\n3. Read Yishuv (Settlement) Data\nA yishuv is a geographically defined place where people live. Use read_cbs_yishuv() to read settlement-level data:\n\n# Read yishuv data with selected columns\ndf_yishuv &lt;- read_cbs_yishuv(\n  path = \"bycode2021.xlsx\",\n  cols = c(1, 2, 5, 13)\n)\n\ndf_yishuv\n\n\n  \n\n\n\nAs you can see, the yishuv id isn‚Äôt following the convention of a 4 digit id. This might cause collisions with regional councils when we will use the yishuv id for municipal level analysis, so we should change it with pad_yishuv_id():\n\ndf_yishuv &lt;- df_yishuv |&gt; \n  mutate(\n    `◊°◊û◊ú ◊ô◊ô◊©◊ï◊ë` = pad_yishuv_id(`◊°◊û◊ú ◊ô◊ô◊©◊ï◊ë`)\n  )\n\n  df_yishuv\n\n\n  \n\n\n\n\n\n4. Read CBS Index Data\nThe package handles both socio-economic status (SES) and peripherality indices at different geographic levels:\n\n\n# Read socio-economic index at municipality level\ndf_ses &lt;- read_cbs_index(\n  path = \"T02.xlsx\",\n  year = 2019,\n  index_type = \"ses\",\n  unit_type = \"muni\"\n)\n\nAvailable options: - Index types: \"ses\" (socio-economic status) or \"peri\" (peripherality) - Unit types: \"muni\" (municipality), \"yishuv\" (settlement), or \"sa\" (statistical area)\nAs in read_cbs_muni(), here too we have to parameters stored in il.cbs.muni:::df_cbs_index_params.\nNow, we have two problems with this data set: 1. The municipal column is for ‚Äústatus‚Äù rather than for id; 2. The yishuv id column isn‚Äôt following the 4-digit convention.\nWe can fix these issues with modify_muni_id() and pad_yishuv_id():\n\ndf_ses &lt;- df_ses |&gt; \n  mutate(\n    muni_id = modify_muni_id(`◊û◊¢◊û◊ì ◊û◊ï◊†◊ô◊¶◊ô◊§◊ú◊ô_MUNICIPAL STATUS`, `◊°◊û◊ú ◊ô◊ô◊©◊ï◊ë_CODE OF LOCALITY`),\n    yishuv_id = pad_yishuv_id(`◊°◊û◊ú ◊ô◊ô◊©◊ï◊ë_CODE OF LOCALITY`),\n    .before = 1\n  )\n\n  df_ses\n\n\n  \n\n\n\n\n\n5. Harmonize Municipal IDs\nIsraeli municipalities have different IDs across government agencies. The read_muni_id() function provides a lookup table:\n\n# Get IDs and names from multiple agencies\nmuni_ids &lt;- read_muni_id(\n  id_types = c(\"muni\", \"edu\", \"tax\"),\n  include_names = TRUE\n)\n\nmuni_ids\n\n\n  \n\n\n\nThis returns: - \"muni\" - CBS municipal IDs and names - \"edu\" - Ministry of Education symbols - \"tax\" - Israel Tax Authority IDs (H.P. numbers)\nYou can use this for your help when you are working with data from The Ministry of Education or non-profits data from Guidestar."
  },
  {
    "objectID": "posts/2025-02-13-il-cbs-muni-0-1-0/index.html#example-workflow",
    "href": "posts/2025-02-13-il-cbs-muni-0-1-0/index.html#example-workflow",
    "title": "Introducing il.cbs.muni - An R Package for handling Israeli CBS Municipal Data",
    "section": "Example Workflow",
    "text": "Example Workflow\nHere‚Äôs a complete example analyzing municipal socio-economic status:\n\nlibrary(il.cbs.muni)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Read SES index data\nses_data &lt;- read_cbs_index(\n  path = \"24_22_375t1.xlsx\",\n  year = 2019,\n  index_type = \"ses\",\n  unit_type = \"muni\"\n) |&gt;\n  # Parse numeric columns\n  mutate(\n    ses_rank = as.numeric(`◊ì◊ô◊®◊ï◊í ◊õ◊ï◊ú◊ú`),\n    ses_cluster = as.numeric(`◊ê◊©◊õ◊ï◊ú ◊õ◊ï◊ú◊ú`)\n  )\n\n# Create visualization\nggplot(ses_data, aes(x = ses_cluster)) +\n  geom_bar(fill = \"steelblue\") +\n  labs(\n    title = \"Distribution of Municipalities by SES Cluster\",\n    x = \"SES Cluster (1=Lowest, 10=Highest)\",\n    y = \"Number of Municipalities\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "posts/2025-02-13-il-cbs-muni-0-1-0/index.html#helper-functions",
    "href": "posts/2025-02-13-il-cbs-muni-0-1-0/index.html#helper-functions",
    "title": "Introducing il.cbs.muni - An R Package for handling Israeli CBS Municipal Data",
    "section": "Helper Functions",
    "text": "Helper Functions\nThe package includes several utility functions:\n\npad_yishuv_id() - Pad yishuv IDs to 4-digit format\nmodify_muni_id() - Modify municipal IDs based on status and yishuv ID\nclean_name() - Clean settlement names from unwanted characters\nrow_to_names_fill() - Elevate rows to column names and fill row-wise"
  },
  {
    "objectID": "posts/2025-02-13-il-cbs-muni-0-1-0/index.html#resources",
    "href": "posts/2025-02-13-il-cbs-muni-0-1-0/index.html#resources",
    "title": "Introducing il.cbs.muni - An R Package for handling Israeli CBS Municipal Data",
    "section": "Resources",
    "text": "Resources\n\nDocumentation: https://matanhakim.github.io/il.cbs.muni/\nSource code: https://github.com/matanhakim/il.cbs.muni\nBug reports: https://github.com/matanhakim/il.cbs.muni/issues\nCRAN page: https://cran.r-project.org/package=il.cbs.muni"
  },
  {
    "objectID": "posts/2025-02-13-il-cbs-muni-0-1-0/index.html#future-plans",
    "href": "posts/2025-02-13-il-cbs-muni-0-1-0/index.html#future-plans",
    "title": "Introducing il.cbs.muni - An R Package for handling Israeli CBS Municipal Data",
    "section": "Future Plans",
    "text": "Future Plans\nI‚Äôm hoping to add:\n\nMore helper functions for common municipal data transformations\nSupport for additional CBS data sources\nVignettes with detailed workflows\nA hex sticker!\nAnything that the Israeli open source community might be interested in"
  },
  {
    "objectID": "posts/2025-02-13-il-cbs-muni-0-1-0/index.html#acknowledgments",
    "href": "posts/2025-02-13-il-cbs-muni-0-1-0/index.html#acknowledgments",
    "title": "Introducing il.cbs.muni - An R Package for handling Israeli CBS Municipal Data",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThis package builds on the excellent work of the Israeli CBS in publishing municipal data. Special thanks to the tidyverse team for creating the tools that make this package possible. Specifically, This package was able to get submitted to CRAN with full tests and input validation thanks to Positron Assistant, which has been a huge blessing.\nHappy analyzing! üìä"
  }
]